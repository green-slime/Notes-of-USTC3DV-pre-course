# Notes-of-USTC3DV-pre-courses

此页面存放学习中记的笔记，更新中（2022/10/5）

## 以下为学习报告

### (2022/08/30∼09/04)
  这周学习了 Numerical Optimazation 的前三章。
  
  简单概括内容，第一章介绍了优化，以及优化问题的各种形式和相关
概念，包括线性/非线性，约束/非约束，凸优化，局部最优/全局最优等。

  第二章开始对无约束优化问题进行展开，介绍了作为后面证明基础的
Taylor 定理，以及简述了线性探测的四种常见方法。提及了置信区域法，但
尚未作详细阐述。

  第三章系统地给出了线性探测的各步骤。首先考虑收敛性和收敛率，给
出选择下降方向的方法；然后选择步长，通过（强）Wolfe 条件，先利用两
个不等式确定一个目标值存在的区间，再调用 Zoom 函数不断缩小区间的
范围，最终取到能够“充分递降”（即满足 Wolfe 条件）的步长值。另外在
第四节还阐述了如何修正 Hessian 矩阵使得修正后的矩阵成为正定，且修
改尽量小。

### (09/05∼09/18)
  第四章论述了置信区域法。thm4.1是最重要的定理，给出了二次型$m_k(p)$取最值的条件。
  第二节提出了柯西点，dogleg和其推广，二维子空间方法。之后分别解释了全局收敛性，
  具体的算法，并在4.4提出引理，证明了thm4.1。最后提了一下简单的改进措施。
  
### (09/19~10/02)
  第五章介绍了共轭梯度法，有我们熟悉的共轭梯度算法Algo5.2，以及进行观察后进行变量代换而成的
  FR方法（Algo5.4）。之后一方面介绍了变量$\beta$的其它取法形成的PR方法等，另一方面考察了这
  些方法的全局收敛性（通过观察梯度列的下确界，如果非0就说明可能不收敛到解）。
